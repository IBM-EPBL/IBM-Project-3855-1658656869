{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Download the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile as zf\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import pickle\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder,LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from skimage import feature\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_spiral = zf.ZipFile(r'dataset1.zip')\n",
    "handle_spiral.extractall('dataset1')\n",
    "handle_spiral.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_train_healthy = os.listdir('dataset1/dataset/spiral/training/healthy/')\n",
    "spiral_train_park = os.listdir('dataset1/dataset/spiral/training/parkinson/')\n",
    "\n",
    "fp_spiral_train_healthy = 'dataset1/dataset/spiral/training/healthy/'\n",
    "fp_spiral_train_park = 'dataset1/dataset/spiral/training/parkinson/'\n",
    "\n",
    "spiral_test_healthy = os.listdir('dataset1/dataset/spiral/testing/healthy/')\n",
    "spiral_test_park = os.listdir('dataset1/dataset/spiral/testing/parkinson/')\n",
    "\n",
    "fp_spiral_test_healthy = 'dataset1/dataset/spiral/testing/healthy/'\n",
    "fp_spiral_test_park = 'dataset1/dataset/spiral/testing/parkinson/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantify_image(image):\n",
    "      features = feature.hog(image,orientations=9,\n",
    "                pixels_per_cell=(10,10),cells_per_block=(2,2),transform_sqrt=True,block_norm=\"L1\")\n",
    "\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting up of training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = []\n",
    "testX = []\n",
    "outputs = []\n",
    "trainY = []\n",
    "testY = []\n",
    "\n",
    "for i in spiral_train_healthy:\n",
    "  image = cv2.imread(fp_spiral_train_healthy+i)\n",
    "  image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.resize(image , (200,200))\n",
    "  image =cv2.threshold(image, 0, 255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "  features = quantify_image(image)\n",
    "  trainX.append(features)\n",
    "  trainY.append('healthy')\n",
    "\n",
    "for i in spiral_train_park:\n",
    "  image = cv2.imread(fp_spiral_train_park+i)\n",
    "  image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.resize(image , (200,200))\n",
    "  image = cv2.threshold(image ,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "  features = quantify_image(image)\n",
    "  trainX.append(features)\n",
    "  trainY.append('parkinson')\n",
    "\n",
    "for i in spiral_test_healthy:\n",
    "  image = cv2.imread(fp_spiral_test_healthy+i)\n",
    "  outputs.append(image)\n",
    "  image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.resize(image , (200,200))\n",
    "  image = cv2.threshold(image ,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "  features = quantify_image(image)\n",
    "  testX.append(features)\n",
    "  testY.append('healthy')\n",
    "\n",
    "for i in spiral_test_park:\n",
    "  image = cv2.imread(fp_spiral_test_park+i)\n",
    "  outputs.append(image)\n",
    "  image = cv2.cvtColor(image , cv2.COLOR_BGR2GRAY)\n",
    "  image = cv2.resize(image , (200,200))\n",
    "  image = cv2.threshold(image ,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "  features = quantify_image(image)\n",
    "  testX.append(features)\n",
    "  testY.append('parkinson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "testX = np.array(testX)\n",
    "trainY = np.array(trainY)\n",
    "testY = np.array(testY)\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "trainY = le.fit_transform(trainY)\n",
    "testY = le.transform(testY)\n",
    "print(trainX.shape,trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model....\")\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(testX)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf = confusion_matrix(testY,preds)\n",
    "cnf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cnf , annot=True , cmap=\"coolwarm\" , cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = metrics.accuracy_score(testY,preds)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = np.random.randint(0,30,25)\n",
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testpath=list(paths.list_images(fp_spiral_train_healthy))\n",
    "idxs=np.arange(0,len(testpath))\n",
    "idxs=np.random.choice(idxs,size=(25,),replace=False)\n",
    "images=[]\n",
    "\n",
    "for i in idxs:\n",
    "    image=cv2.imread(testpath[i])\n",
    "    output=image.copy()\n",
    "    output=cv2.resize(output,(128,128))\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    image=cv2.resize(image,(200,200))\n",
    "    image=cv2.threshold(image,0,255,cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    features= quantify_image(image)\n",
    "    preds=model.predict([features])\n",
    "    label=le.inverse_transform(preds)[0]\n",
    "    if label==\"healthy\":\n",
    "      color=(0,255,0) \n",
    "    else:\n",
    "      (0,0,255)\n",
    "    cv2.putText(output,label, (3,20),cv2.FONT_HERSHEY_SIMPLEX,0.5,color,2)\n",
    "    images.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage=build_montages(images,(128,128),(5,5))[0]\n",
    "cv2_imshow(montage)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the model-Accuracy and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)\n",
    "\n",
    "cm = confusion_matrix(testY, predictions).flatten()\n",
    "print(cm)\n",
    "(tn, fp, fn, tp) = cm\n",
    "accuracy = (tp + tn) / float(cm.sum())\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model,open('parkinson.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
